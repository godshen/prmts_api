# 中期检查报告

## 全文提要

1. 对目前购置的服务器，以及服务器上部署的服务应用做一个说明，以便完成用例测试

2. 对照**交付与验收标准的5个case**进行展示，并且提供操作步骤以供复现算法效果
3. 当前项目的总结工作

## 1）服务器及程序部署说明

### 1.1）整体信息

目前已经在华为云上购置了4 台服务器，其中 3 台用于部署 k 8s 集群（这三台统称 k 8s 集群服务器），剩下一台用于放置测试、开发环境（下称测试服务器）。

### 1.2）账号信息

**提供华为云的账号和密码以便检查服务部署情况**

- 账号：pmlpml0928
- 密码：yuy3226

**提供测试服务器的用户名+密码/密钥以便检查测试服务器的部署情况**

- IP：139.9.204.5
- 用户名：workflow
- 密码：yuy3226
- 密钥：“huawei_server_workflow_id_rsa”文件

### 1.3）程序部署情况

#### 1.3.1）进行实例扩缩的单服务productpage

![1563024933057](assets\1563024933057.png)

productpage服务是istio自带的bookinfo样例的其中的一个服务，在本实验中，因为我们的研究背景是单服务场景，所以我们切断了productpage服务与bookinfo其他服务的联系，将productpage作为一个单服务来提供服务。

#### 1.3.2）服务实例扩缩算法的工作负载

![1563024903717](assets\1563024903717.png)

共有如下详细描述中的4个工作负载，共三种算法：

1. static-scale工作负载：静态阈值法扩缩实例（响应式算法）
2. qlearning-scale工作负载：qlearning 算法扩缩实例（响应式算法）
3. armia-predict-scale工作负载：arima 预测算法扩缩实例（预测式算法）
4. armia-predict工作负载：将预测结果发送到 Prometheus 服务器中，用于与实际负载以验证预测结果的准确性（默认启动，表示持续预测结果）

#### 1.3.3）流量测试工具Gatling

![1563024887450](assets\1563024887450.png)

测试服务器中，已经放置好发送特定流量波形的工具 gatling ，在登录**测试服务器**发送流量后，可以通过 http://139.9.204.5:18890/ 查看发送流量的结果。

#### 1.3.4）指标可视化工具Grafana

通过 grafana 面板可视化响应时间 、 cpu 使用率、实例数量变化等指标，通过
http://139.9.57.167:3000访 问 grafana 面板，我们已经为 3 个算法定义了三种面板，如图所示：

![1563024865368](assets\1563024865368.png)

![1563024848973](assets\1563024848973.png)

## 2）SLA工作任务书完成情况

该章节的组织方式是这样的：

1. 首先，描述华为方给定的SLA任务书中相应的任务
2. 然后，从以下2个方面来描述3个实例扩缩算法
   - 算法使用的指标
   - 算法在实例扩缩场景中的简要介绍
3. 接着单独描述离线预测方法
4. 之后，展示实例扩缩算法和离线预测算法的结果
5. 最后，对中期完成情况做一个总结

### 2.1）任务要求

1.  基于响应时间的自动扩缩容。基于配置的自动扩缩容策略，根据收集到的特定服务的响应时间做自动的扩容和缩容；
2.  基于容量自动扩缩容。基于配置的自动扩缩容策略，根据收集到的特定服务的请求数做自动的扩容和缩容；


## 2.2）实例扩缩算法

#### 2.2.1）静态阈值响应式方法（static-scale）

##### 1）所用指标

- 错误率，使用promethues语句查询并显示在Grafana中，语句如下：<br>
```
100*
(sum(delta(istio_requests_total{destination_app='productpage',source_workload='istio-ingressgateway',reporter='destination'}[30s]))-sum(delta(istio_requests_total{destination_app='productpage',response_code='200',source_workload='istio-ingressgateway',reporter='destination'}[30s])))/sum(delta(istio_requests_total{destination_app='productpage',source_workload='istio-ingressgateway',reporter='destination'}[30s]))
```



- 响应时间
使用promethues语句查询并显示在Grafana中，语句如下：<br>
```
1000 * sum(delta(istio_request_duration_seconds_sum{destination_app="productpage",source_workload='istio-ingressgateway',reporter='destination'}[30s]))/sum(delta(istio_request_duration_seconds_count{destination_app="productpage",source_workload='istio-ingressgateway',reporter='destination'}[30s]))
```

- 实例数
使用promethues语句查询并显示在Grafana中，语句如下：<br>
```
count(sum(rate(container_cpu_usage_seconds_total{image!="",pod_name=~'productpage.*'}[1m])) by (pod_name, namespace))
```


##### 2）算法介绍

1.根据应用的平均响应时间以及访问应用的错误率来设定阈值，当相应指标达到阈值上界时，增加实例数直到指标低于阈值上界。当相应指标达到阈值下界时，减少实例数直到指标高于阈值下界。当指标在上界和下界之间时，不进行增加/减少实例的操作。<br><br>
2.根据大量的论文阅读以及对华为云的实际操作经验可以得出，目前响应时间的上界较为合理的值是250ms，响应时间的下界较为合理的是70ms，错误率的上界较为合理的是0.7%（错误率未设下界）。如果响应时间的上界和下界设置的过近的话会产生抖动现象。<br><br>
3.目前为了避免抖动情况的发生，算法周期设置为25s，即每25s进行一次平均响应时间以及错误率的获取并判断是否需要进行扩缩容操作。

##### 2.2.1.4）case完成效果

| Case  | Case 目标                                                    | 完成情况 |
| :---: | ------------------------------------------------------------ | -------- |
| case1 | 租户服务时延（请求数）增大时，扩容及时性验收：1、构造目标服务时延，以及满足配置的扩容标准；2、观察服务实例自动扩容，扩容时间满足要求。 | √        |
| case2 | 租户服务时延（请求数）减小时，缩容及时性验收：1、构造目标服务时延，以及满足配置的缩容标准；2、观察服务实例自动扩容，缩容时间满足要求。 | √        |
| case4 | 租户服务时延快速变化时，扩容及时和有效性验收：1、构造目标服务时延骤变，以及满足配置的扩容标准；2、观察服务实例自动扩容，扩容时间满足要求，避免多次扩容动作。 | √        |

#### 2.2.2）QLearning响应式方法（Qlearning-scale）

##### 1）所用指标
- CPU利用率，使用promethues语句查询并显示在Grafana中，语句如下：<br>
```
sum(rate(container_cpu_usage_seconds_total{image!="",pod_name=~'productpage.*'}[1m])) / sum(container_spec_cpu_quota{image!="",pod_name=~'productpage.*'} / container_spec_cpu_period{image!="",pod_name=~'productpage.*'}) * 100
```
- 错误率，使用promethues语句查询并显示在Grafana中，语句如下：<br>
```
100*
(sum(delta(istio_requests_total{destination_app='productpage',source_workload='istio-ingressgateway',reporter='destination'}[30s]))-sum(delta(istio_requests_total{destination_app='productpage',response_code='200',source_workload='istio-ingressgateway',reporter='destination'}[30s])))/sum(delta(istio_requests_total{destination_app='productpage',source_workload='istio-ingressgateway',reporter='destination'}[30s]))
```
- 响应时间，使用promethues语句查询并显示在Grafana中，语句如下：<br>
```
1000 * sum(delta(istio_request_duration_seconds_sum{destination_app="productpage",source_workload='istio-ingressgateway',reporter='destination'}[30s]))/sum(delta(istio_request_duration_seconds_count{destination_app="productpage",source_workload='istio-ingressgateway',reporter='destination'}[30s]))
```
- 实例数，使用promethues语句查询并显示在Grafana中，语句如下：<br>
```
count(sum(rate(container_cpu_usage_seconds_total{image!="",pod_name=~'productpage.*'}[1m])) by (pod_name, namespace))
```

##### 2）算法介绍

1.算法定义：Q-Learning算法是根据系统历史的性能与负载以及当前的性能与负载来确定对应模型（Q矩阵）的无状态的算法。在每一个状态执行不同的动作都会得出不同的Q值，Q值受回报值和α，γ参数的影响。算法分为模型训练过程和应用过程两个部分，其中模型训练过程需要在各个状态下都尝试不同的动作并记录对应的Q值，存储到Q矩阵中。应用过程只需要直接查询Q矩阵选取收益最大的动作即可。<br><br>
2.模型建立：平均响应时间分为6个区间，CPU使用率分为7个区间。每个区间都有对应的期望值。根据平均响应时间，CPU使用率这两个个指标加权来确定系统每个状态的期望值以及进行某个动作后到达另一种状态的回报值（每个状态都由平均响应时间对应的区间，CPU使用率对应的区间构成，系统一共有6*7种状态）使用二维数组来存储Q(st,at)的值，其中初始值全部为0。其中行代表每一种状态（一共42种），列代表实例数减少2,实例数减少1，实例数不变，实例数增加1，实例数增加2这五种操作（目前进行了很多的剪枝操作，并不是每个状态都进行五种操作）。<br><br>
3.执行过程：训练过程中首先获取应用当前的平均响应时间和CPU使用率。得到当前状态后对应用进行扩容/缩容/不变几种操作并再次分别检测状态，根据之前制定的回报值哈希表来确定进行操作后的回报值，之后更新对应的Q值。<br>
之后程序会周期性的重复上述步骤，当负载增加或减少时，Q值都会被改变，负载种类足够多的话，代表Q值的二维数组的每个元素都会得到改变。
经过一定的迭代后，代表Q的二维数组的元素值都会趋于稳定，即该算法收敛。算法收敛后就可以进入应用模式，之后直接根据MAX Q(st+1,a)来改变实例数完成状态t到状态t+1的转换即可（但是在实际应用中遇到剧变的流量时，还会自动进行边学习边训练，如上个周期操作后的状态和当前周期的状态相差很大的话就会进行训练）。

#### 2.2.3）ARIMA预测式方法（Arima-scale）

##### 1）所用指标

- CPU利用率,使用promethues语句查询并显示在Grafana中，语句如下：<br>
```
sum(rate(container_cpu_usage_seconds_total{image!="",pod_name=~'productpage.*'}[1m])) / sum(container_spec_cpu_quota{image!="",pod_name=~'productpage.*'} / container_spec_cpu_period{image!="",pod_name=~'productpage.*'}) * 100
```
- 内存使用率,使用promethues语句查询并显示在Grafana中，语句如下：<br>
```
sum(sum(container_memory_rss{image!="",pod_name=~"productpage.*"})/sum(container_spec_memory_limit_bytes{image!="",pod_name=~"productpage.*"}))
```

- 实际负载（用于预测）,使用promethues语句查询并显示在Grafana中，语句如下：<br>
```
sum(rate(istio_requests_total{destination_app='productpage',source_workload='istio-ingressgateway',reporter='destination'}[30s]))
```

- 预测负载,使用promethues语句查询并显示在Grafana中，语句如下：（该指标是自定义的指标，由运行在云上的预测器工作负载产生的指标）<br>
```
workflow_predict_workload_v2
```
- 实例数，使用promethues语句查询并显示在Grafana中，语句如下：<br>
```
count(sum(rate(container_cpu_usage_seconds_total{image!="",pod_name=~'productpage.*'}[1m])) by (pod_name, namespace))
```

##### 2）算法介绍

1.首先使用prometheus获取前几个周期的负载，之后获取当前周期的负载。然后根据前面获取到的数据（目前经常使用前三个周期的负载和当前周期的负载）来预测出下个周期的负载。<br><br>
2.获取应用当前实例数，并确定下个周期实例数可能取值的范围。<br><br>
3.将范围内的实例数分别应用到下个周期并进行响应时间的预测（先根据当前周期CPU利用率以及内存使用率以及下个周期想要部署的实例数使用MVA算法预测下个周期的这两个指标的值，然后对下个周期的响应时间进行预测），如果响应时间超过SLA的界限，就舍弃该实例数。<br><br>
4.通过考虑部署成本，使用实例的成本以及SLA违约成本计算下个周期不同实例数对应的不同成本。最低成本对应的实例数就是要改变到的实例数数目。<br><br>
5.ARMA的算法周期是15s，可以较快的根据预测的流量（目前预测流量的效果与实际值以及趋势很贴近）进行实例扩缩。


### 2.3）离线预测

#### 实验原理

时间序列预测算法是通过给定若干个之后的时间点上的数据，进而预测出之后数据的算法。本文使用了时序预测中较为常见的滑动窗口处理，即对于t时刻的流量数据$f(X_t)$，用过去的i个时间点的数据进行预测，问题定义上形如$f(X_{t-i},X_{t-i+1},...,X_{t-1})=f(X_{t})$。因此我们的任务就是使用算法来模拟出这个映射函数$f$。

算法层面上有论文中比较常用的arima，工业上比较经常见到的facebook prophet，以及在其他领域（语义识别、量化投资）中类似问题出现过，但是较少在流量预测中见到的机器学习回归方法与循环神经网络。

- 对于机器学习回归方法，选用了效果比较好的svr。
- 对于循环神经网络，选用了比较容易实现的LSTM。

对于预测的方式，考虑到给定的数据规模可能不够大，给出了两种：

- 滑动窗口整体预测，即用前80%的数据来训练算法，拟合函数$f$，然后用产生的这个函数去预测后20%的数据。
- 滑动窗口部分预测，即用前40$的数据来初始化模型，然后对于后60%的数据，在预测的同时使用已有的数据再次训练模型。这样子即使离线训练的时候数据规模不大，后续也有继续完善的可能。

### 2.4）实验测试结果展示

#### 2.4.1）静态阈值响应式方法（static-scale）

##### 1. 实验步骤

- 按照1.2中的测试服务器信息登陆测试服务器之后，执行以下命令

```bash
kubectl scale deploy static-scale --replicas=1 # 开启算法
~/gatling/bin/gatling.sh # 发送测试流量，实验结果是发送0号流量的结果
```

- 打开Grafana监控面板[链接](<http://139.9.57.167:3000/d/ekqEZKSZz/productpage-yu-zhi-fa?refresh=5s&orgId=1&from=now-15m&to=now>)查看实例扩缩效果

- 在流量发送完毕后，执行如下命令，并且打开[该链接](http://139.9.204.5:18890/)查看发送的流量波形

```bash
cd ~/gatling/results/
python3 -m http.server 18890
```

- 执行以下命令，停止静态阈值法，以便执行其他算法

```bash
kubectl scale deploy static-scale --replicas=0 # 停止算法
```

##### 2. 实验效果

以多种二次函数组合的波形为例，静态阈值法的效果图如下：

![静态阈值法效果图图4](assets/%E9%9D%99%E6%80%81%E9%98%88%E5%80%BC%E6%B3%95%E6%95%88%E6%9E%9C%E5%9B%BE%E5%9B%BE4.png)

![静态阈值法效果图图2](assets/%E9%9D%99%E6%80%81%E9%98%88%E5%80%BC%E6%B3%95%E6%95%88%E6%9E%9C%E5%9B%BE%E5%9B%BE2.png)

![静态阈值法效果图图3](assets/%E9%9D%99%E6%80%81%E9%98%88%E5%80%BC%E6%B3%95%E6%95%88%E6%9E%9C%E5%9B%BE%E5%9B%BE3.png)

可以看出，根据响应时间和错误率设置的上界和下界合理的阈值法，可以较为正确的根据流量
对应用进行实例扩缩。不过该算法作为响应式算法具有一定的延迟。

要注意的是，对于静态阈值法，如果阈值的上界和下界过近的话，就会产生抖动现象。

#### 2.4.2）QLearning响应式方法（Qlearning-scale）

##### 1）实验步骤

- 按照1.2中的测试服务器信息登陆测试服务器之后，执行以下命令

```bash
kubectl scale deploy qlearning-scale --replicas=1 # 开启算法
~/gatling/bin/gatling.sh # 发送测试流量，实验结果是发送0号流量的结果
```

- 打开Grafana监控面板[链接](<http://139.9.57.167:3000/d/ekqEZKSZz/productpage-yu-zhi-fa?refresh=5s&orgId=1&from=now-15m&to=now>)查看实例扩缩效果

- 在流量发送完毕后，执行如下命令，并且打开[该链接](http://139.9.204.5:18890/)查看发送的流量波形

  ```bash
  cd ~/gatling/results/
  python3 -m http.server 18890
  ```

- 执行以下命令，停止该算法，以便执行其他算法

  ```
  kubectl scale deploy qlearning-scale --replicas=0 # 停止算法
  ```

##### 2）实验效果

首先使用特定的波形进行Q-Learning算法的模型训练环节，其波形图如下（）：

![Q-Learning算法效果图图4](assets/Q-Learning%E7%AE%97%E6%B3%95%E6%95%88%E6%9E%9C%E5%9B%BE%E5%9B%BE4.png)

得到训练好的模型以后，算法就可以进入到应用模式（即遇到剧变的流量的时候再进行学习，否则
只应用训练好的Q矩阵进行下一个收益最大的动作的选取）。

以多种二次函数组合的波形为例，Q-Learning算法的效果图如下：

![Q-Learning效果图图1](assets/Q-Learning%E6%95%88%E6%9E%9C%E5%9B%BE%E5%9B%BE1.png)

![Q-Learning效果图图2](assets/Q-Learning%E6%95%88%E6%9E%9C%E5%9B%BE%E5%9B%BE2.png)

与静态阈值法一样，Q-Learning算法也是响应式的算法，因此也会具有一定的延迟现象，不过该算法会基于以往的经验进行学习，其延迟要比静态阈值法的小，且该算法不会产生抖动现象。

#### 2.4.3）ARIMA预测式方法（Arima-scale）

##### 1）实验步骤

- 按照1.2中的测试服务器信息登陆测试服务器之后，执行以下命令

```bash
kubectl scale deploy armia-predict-scale --replicas=1 # 开启算法
~/gatling/bin/gatling.sh # 发送测试流量，实验结果是发送0号流量的结果
```

- 打开Grafana监控面板[链接](<http://139.9.57.167:3000/d/ekqEZKSZz/productpage-yu-zhi-fa?refresh=5s&orgId=1&from=now-15m&to=now>)查看实例扩缩效果

- 在流量发送完毕后，执行如下命令，并且打开[该链接](http://139.9.204.5:18890/)查看发送的流量波形

  ```bash
  cd ~/gatling/results/
  python3 -m http.server 18890
  ```

- 执行以下命令，停止该算法，以便执行其他算法

  ```bash
  kubectl scale deploy armia-predict-scale --replicas=0 # 停止算法
  ```

##### 2）实验效果

![ARMA算法效果图图1](assets/ARMA%E7%AE%97%E6%B3%95%E6%95%88%E6%9E%9C%E5%9B%BE%E5%9B%BE1.png)

![ARMA算法效果图图2](assets/ARMA%E7%AE%97%E6%B3%95%E6%95%88%E6%9E%9C%E5%9B%BE%E5%9B%BE2.png)

![ARMA算法效果图图3](assets/ARMA%E7%AE%97%E6%B3%95%E6%95%88%E6%9E%9C%E5%9B%BE%E5%9B%BE3.png)

![ARMA算法效果图图4](assets/ARMA%E7%AE%97%E6%B3%95%E6%95%88%E6%9E%9C%E5%9B%BE%E5%9B%BE4.png)

可以看出，ARMA算法通过提前对下个周期的负载以及下个周期的对应实例数得到的响应时间进行了预测，从而使得延迟现象很小，实例数会紧密随着负载的变化而变化。

此外ARMA算法的周期性也较短，可以做到较为快速的实例扩缩。

#### 2.4.4）离线数据预测演示

##### 1）数据集

- 使用了Kaggle上Google举办的web traffic time series中提供的数据，为维基百科各个页面上的数据（两年时间，以天为单位）。本次预测使用平均访问数量最高的一个，数量级为10^7，持续时间550天。
- 前80%作为训练集，后20%作为测试集

所用数据波形如下：

![1563024767771](assets/1563024767771.png)

- 考虑到kaggle上的数据的规律性并不强，使用了十个随机的正弦函数叠加作为更加有规律的测试信号来检验算法在有较强周期性信号上的表现。

![signal](assets/signal.png)

##### 2）实验效果

因为篇幅问题，仅展示各个算法在kaggle数据上的整体预测表现图片。其中arima与facebook prophet因为算法的缘故是直接使用80%的数据预测后20%的数据，其他都是使用滑动窗口处理数据并进行预测。

1. ARIMA整体预测

![arima](assets/arima.png)

预测时间为0.4s，可以看到预测出了大致的趋势，但是无法预测细节。

2. facebook Prophet算法

![prophet](assets/facebook.png)

可能对于长期、有规律的时序数据表现会更好，但是对于这种变化比较突然的数据表现不佳。

3. lstm算法

![lstm](assets/lstm.png)

4. 机器学习回归-svr

![svr](assets/svr.png)

总结表格：考虑到效果问题，最后只进行了LSTM和SVR的效果比较

PS：kaggle数据的数据量比较大（结果为进行逆归一化）

|                  | 使用数据 | 使用模型 | MSE            | 训练时间 | 单次训练时间 |
| ---------------- | -------- | -------- | -------------- | -------- | ------------ |
| 滑动窗口整体预测 | kaggle   | LSTM     | $8.9*10^{12}$  | 62s      | 无           |
| 滑动窗口整体预测 | kaggle   | SVR      | $1.05*10^{13}$ | 0.12s    | 无           |
| 滑动窗口在线预测 | kaggle   | LSTM     | $9.3*10^{13}$  | 50.05s   | 0.862s       |
| 滑动窗口在线预测 | kaggle   | SVR      | $9.5*10^{13}$  | 0.00009s | 0.0004s      |
| 滑动窗口整体预测 | 模拟     | LSTM     | $0.3809$       | 32s      | 无           |
| 滑动窗口整体预测 | 模拟     | SVR      | $00.09$        | 0.09s    | 无           |
| 滑动窗口在线预测 | 模拟     | LSTM     | $0.269$        | 44.5s    | 0.8226s      |
| 滑动窗口在线预测 | 模拟     | SVR      | $0.356$        | 0.002s   | 0.002s       |

结果总结：

在数据充足的情况下，SVR在模拟数据上表现较好，在kaggle数据上表现不如LSTM。在数据不那么充足的时候，需要部分在线预测的时候，LSTM的表现都更加地优秀。

但是SVR的超参数设置上更加的容易，同时运行速度远远快于LSTM。因此考虑到机器性能限制，机器学习回归方法应该会有更好的表现。

### 2.5）结论与讨论

#### 2.5.1）任务完成整体情况

| 评价任务标准                                                 | 完成情况                                                     |
| :----------------------------------------------------------- | :----------------------------------------------------------- |
| 1、在华为云CCE集群上启用Istio服务网格进行验证                | 已完成，顺利启动Istio服务网格，并且通过Prometheus插件获取到了相应的监控指标，也能通过Grafana插件对监控到的指标进行可视化 |
| 2、实时算法：通过“验收方法”的前四个case展开验证，在实际指标变化30s内判定并执行扩缩容动作；避免抖动，避免多此持续扩容 | 4个case除了抖动问题外均已完成研究，抖动问题尚需双方商议      |
| 3、离线预测：通过“验收方法”中的Case5进行验收，离线算法能准确预测并执行扩容操作，准确率80%。提前量不大于600秒 | 已完成，基于google开源真实的离线业务数据进行预测             |

#### 2.5.2）任务case完成情况

| Case 验收标准                                                | 完成情况 |
| ------------------------------------------------------------ | -------- |
| 租户服务时延（请求数）增大时，扩容及时性验收：1、构造目标服务时延，以及满足配置的扩容标准；2、观察服务实例自动扩容，扩容时间满足要求。 | √        |
| 租户服务时延（请求数）减小时，缩容及时性验收：1、构造目标服务时延，以及满足配置的缩容标准；2、观察服务实例自动扩容，缩容时间满足要求。 | √        |
| 租户服务时延快速变化时，扩容及时和有效性验收：1、构造目标服务时延骤变，以及满足配置的扩容标准；2、观察服务实例自动扩容，扩容时间满足要求，避免多次扩容动作。 | √        |
| 扩缩容预测有效性和准确性验证：1、选择实际租户典型服务，以天、月、年为周期构造访问数据，并离线学习；2、在下个周期实际的访问数据上执行扩缩容判定，结合实际运行指标，验证预测准确性和有效性 | √        |

#### 2.5.3）任务相关讨论

**部分变更**

1. 指标太少 -> 扩充指标，不止是包含响应时间和请求数，还应该包含cpu、内存利用率等指标。

   由于**基于响应时间的自动扩缩容算法**和**基于请求数自动扩缩容**只是对于**响应时间**和**请求数**二者指标不一致，在我们的实际研究开展过程中，**发现两个指标对于算法而言不是很足够**，所以，在设计算法进行的实验里，我们往往综合考虑请求数和响应时间，并且加上一些额外指标，例如：cpu利用率，内存利用率，请求错误率等指标，在接下来的实验结果中我们可以看到，在综合考虑这些指标前提下，可以得到较好的效果。

2. 抖动问题

   需要双方进一步磋商交流后续事宜安排。

**额外工作**

1. 多指标结合

   在研究中，我们设计出了多指标结合的算法，并且取得很好的效果

2. 预测式方法

   在研究中，我们发现除了在SLA任务书中提出的响应式方法外，预测式方法也是一个不错的思路，并且将在线预测式方法部署在了k8s集群中，我们可以在上述实验展示部分中看到，我们的预测方法取得很不错的效果。

3. 设计并且完成3个实例扩缩算法

   已经部署到集群里，并且能取得很好的效果。

#### 2.5.4）中期检查总结

在实际研究开展过程中，除了SLA任务书中给的”响应时间“和”流量“这两个指标外，还结合实际情况，主要受启发于我们研读的论文，为了使得算法更加高效、准确，一般在综合考虑”响应时间“+”流量“之外，还需要了新的cpu、内存利用率以及错误率等指标，这些指标的加入，使得算法能够呈现出较好的效果，符合学术界前沿算法的设计方式。

除了响应式方法之外，还设计并且实现出了预测式方法，作为响应式方法的一个补充。

总的来说，除了抖动问题还需要双方磋商外，其他方面，算是超额完成了任务。